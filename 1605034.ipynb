{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "rs = RandomState(MT19937(SeedSequence()))\n",
    "np.random.seed(12345679)\n",
    "\n",
    "\n",
    "toy_test = open(\"data/toy/testNN.txt\", \"r\")\n",
    "toy_train = open(\"data/toy/trainNN.txt\", \"r\")\n",
    "\n",
    "# loop until end of file\n",
    "test_input = []\n",
    "train_input = []\n",
    "\n",
    "for line in toy_test:\n",
    "    # split line into words\n",
    "    words = line.split()\n",
    "    # convert words to float\n",
    "    for i in range(len(words)):\n",
    "        words[i] = float(words[i])\n",
    "    # append words to list\n",
    "    test_input.append(words)\n",
    "\n",
    "for line in toy_train:\n",
    "    # split line into words\n",
    "    words = line.split()\n",
    "    # convert words to float\n",
    "    for i in range(len(words)):\n",
    "        words[i] = float(words[i])\n",
    "    # append words to list\n",
    "    train_input.append(words)\n",
    "\n",
    "\n",
    "# split X and Y\n",
    "test_X = []\n",
    "test_Y = []\n",
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "# take last column as Y\n",
    "for i in range(len(test_input)):\n",
    "    test_Y.append(int(test_input[i][-1]))\n",
    "    test_X.append(test_input[i][:-1])\n",
    "\n",
    "for i in range(len(train_input)):\n",
    "    train_Y.append(int(train_input[i][-1]))\n",
    "    train_X.append(train_input[i][:-1])\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)\n",
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)\n",
    "\n",
    "\n",
    "# normalize with mean and std\n",
    "train_X = (train_X - np.mean(train_X, axis=0)) / np.std(train_X, axis=0)\n",
    "test_X = (test_X - np.mean(test_X, axis=0)) / np.std(test_X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.508\n"
     ]
    }
   ],
   "source": [
    "# backprop algo implementation\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_der(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "# DERIVATIVE OF ReLu FUNCTION\n",
    "def ReLU_der(z):\n",
    "    return np.array(z>0, dtype=float)\n",
    "\n",
    "def cost_der(a,y):\n",
    "    return (a-y)\n",
    "\n",
    "\n",
    "def backprop(B,W,structure,x,y):\n",
    "    \n",
    "    delJdelB = [np.zeros(b.shape) for b in B]\n",
    "    delJdelW = [np.zeros(w.shape) for w in W]\n",
    "\n",
    "    Z = []\n",
    "    A = []\n",
    "    # ---------- forward pass ----------   \n",
    "    x = np.array(x).reshape(len(x),1)\n",
    "    for b, w in zip(B, W):\n",
    "        if len(Z) == 0:\n",
    "            Z.append(np.dot(w.T,x) + b)\n",
    "        else:\n",
    "            Z.append(np.dot(w.T, A[-1]) + b)\n",
    "\n",
    "        A.append(ReLU(Z[-1])) \n",
    "    \n",
    "\n",
    "    H = len(structure)-2 # number of hidden layers\n",
    "\n",
    "    for l in range(H,-1,-1):\n",
    "    \n",
    "        if l == H:\n",
    "            delJdelB[l] = cost_der(A[l], y) * ReLU_der(Z[l])\n",
    "        else:\n",
    "            delJdelB[l] = ReLU_der(Z[l]) * np.dot( W[l+1],delJdelB[l+1]) \n",
    "    \n",
    "        if l == 0:\n",
    "            delJdelW[l] = np.dot(x.T,delJdelB[l-1])\n",
    "        else:\n",
    "            delJdelW[l] = np.dot(A[l-1],delJdelB[l].T) #doubt\n",
    "    \n",
    "\n",
    "    return delJdelW, delJdelB\n",
    "\n",
    "\n",
    "def gradient_descent(B,W,structure,mini_batch, eta) :\n",
    "    delJdelB = [np.zeros(b.shape) for b in B]\n",
    "    delJdelW = [np.zeros(w.shape) for w in W]\n",
    "\n",
    "    for x, y in mini_batch:\n",
    "        dJdw, dJdb = backprop(B,W,structure,x, y)\n",
    "        delJdelB = [b + dJdb[i] for i, b in enumerate(delJdelB)]\n",
    "        delJdelW = [w + dJdw[i] for i, w in enumerate(delJdelW)]\n",
    "    \n",
    "    B = [b - (eta/len(mini_batch)) * dJdb[i] for i, b in enumerate(B)]\n",
    "    W = [w - (eta/len(mini_batch)) * dJdw[i] for i, w in enumerate(W)]\n",
    "\n",
    "\n",
    "def train(structure,train_X, train_Y, epochs, eta):\n",
    "    \n",
    "    B = [np.random.randn(l, 1) for l in structure[1:]] \n",
    "    W = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "\n",
    "    for i in range(epochs):\n",
    "        mini_batch = list(zip(train_X, train_Y))\n",
    "        np.random.shuffle(mini_batch)\n",
    "        mini_batch = mini_batch[:len(train_X)]\n",
    "        gradient_descent(B,W,structure,mini_batch, eta)\n",
    "\n",
    "    return B, W\n",
    "\n",
    "\n",
    "num_of_class = len(set(test_Y))\n",
    "num_of_input_features = len(test_X[0])\n",
    "        \n",
    "neu_net = [num_of_input_features,5,num_of_class]\n",
    "B, W = train(neu_net, train_X, train_Y, 100, 0.1)\n",
    "\n",
    "\n",
    "# test the model\n",
    "\n",
    "# get the prediction from given weights and biases and input\n",
    "def predict(B,W,x):\n",
    "    Z = []\n",
    "    A = []\n",
    "\n",
    "\n",
    "    # make X a column vector\n",
    "    x = np.array(x).reshape(len(x),1)\n",
    "\n",
    "    for b, w in zip(B, W):\n",
    "        if len(Z) == 0:\n",
    "            Z.append(np.dot(w.T,x) + b)\n",
    "        else:\n",
    "            Z.append(np.dot(w.T, A[-1]) + b)\n",
    "\n",
    "        A.append(ReLU(Z[-1])) \n",
    "    \n",
    "    return A[-1]\n",
    "\n",
    "\n",
    "y = predict(B,W,test_X[0]) \n",
    "\n",
    "y_pred = []\n",
    "for x in test_X:\n",
    "    y_pred.append(np.argmax(predict(B,W,x))+1)\n",
    "    #y_pred.append(predict(B,W,x))\n",
    "\n",
    "# print accuracy\n",
    "accuracy = 0\n",
    "for i in range(len(test_Y)):\n",
    "    if test_Y[i] == y_pred[i]:\n",
    "        accuracy += 1\n",
    "\n",
    "print(\"Accuracy\", accuracy/len(test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6f8c3de90b578c42c5dca1ace0652505f65d16b2ece0eaf147a9cf03f55f9e2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
